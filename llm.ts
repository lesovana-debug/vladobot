import OpenAI from 'openai';
import { openaiConfig } from './config';
import { logger } from './logging';

/**
 * LLM Provider interface for abstraction
 */
export interface LLMProvider {
  generateSummary(messages: ProcessedMessage[], context: SummaryContext): Promise<string>;
  isAvailable(): Promise<boolean>;
}

/**
 * Processed message for summarization
 */
export interface ProcessedMessage {
  id: string;
  user: {
    username: string | null;
    firstName: string;
    lastName: string | null;
  };
  type: 'text' | 'photo' | 'video' | 'voice' | 'audio' | 'video_note' | 'sticker' | 'document';
  content: string | null;
  transcript?: string;
  timestamp: string;
  replyTo?: string;
}

/**
 * Context for summary generation
 */
export interface SummaryContext {
  chatTitle: string;
  date: string;
  totalMessages: number;
  targetUsername: string;
}

/**
 * OpenAI LLM Provider implementation
 */
export class OpenAIProvider implements LLMProvider {
  private client: OpenAI;

  constructor() {
    this.client = new OpenAI({
      apiKey: openaiConfig.apiKey,
    });
  }

  /**
   * Generate daily summary using OpenAI
   */
  public async generateSummary(messages: ProcessedMessage[], context: SummaryContext): Promise<string> {
    try {
      const prompt = this.buildPrompt(messages, context);
      
      logger.info('Generating summary with OpenAI', {
        messageCount: messages.length,
        chatTitle: context.chatTitle,
        date: context.date,
      });

      const response = await this.client.chat.completions.create({
        model: openaiConfig.model,
        messages: [
          {
            role: 'system',
            content: `–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ —á–∞—Ç–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Å–æ–∑–¥–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏ –ø–µ—Ä–µ–ø–∏—Å–∫–∏ –∑–∞ –¥–µ–Ω—å. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.`
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 1000,
        temperature: 0.7,
      });

      const summary = response.choices[0]?.message?.content;
      if (!summary) {
        throw new Error('Empty response from OpenAI');
      }

      logger.info('Summary generated successfully', { 
        tokenUsage: response.usage,
        summaryLength: summary.length 
      });

      return summary;
    } catch (error) {
      logger.error('Failed to generate summary', { error: error instanceof Error ? error.message : error });
      throw error;
    }
  }

  /**
   * Check if OpenAI API is available
   */
  public async isAvailable(): Promise<boolean> {
    try {
      await this.client.models.list();
      return true;
    } catch (error) {
      logger.warn('OpenAI API not available', { error: error instanceof Error ? error.message : error });
      return false;
    }
  }

  /**
   * Build prompt for summary generation
   */
  private buildPrompt(messages: ProcessedMessage[], context: SummaryContext): string {
    const messageTexts = messages.map(msg => {
      const userDisplay = msg.user.username ? `@${msg.user.username}` : msg.user.firstName;
      const time = new Date(msg.timestamp).toLocaleTimeString('ru-RU', { 
        hour: '2-digit', 
        minute: '2-digit' 
      });
      
      let content = '';
      switch (msg.type) {
        case 'text':
          content = msg.content || '[–ø—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ]';
          break;
        case 'photo':
          content = `[—Ñ–æ—Ç–æ] ${msg.content || ''}`;
          break;
        case 'video':
          content = `[–≤–∏–¥–µ–æ] ${msg.content || ''}`;
          break;
        case 'voice':
        case 'audio':
          content = `[–≥–æ–ª–æ—Å–æ–≤–æ–µ] ${msg.transcript || '[–Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å]'}`;
          break;
        case 'video_note':
          content = `[–∫—Ä—É–∂–æ–∫] ${msg.transcript || '[–Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å]'}`;
          break;
        case 'sticker':
          content = '[—Å—Ç–∏–∫–µ—Ä]';
          break;
        case 'document':
          content = `[–¥–æ–∫—É–º–µ–Ω—Ç] ${msg.content || ''}`;
          break;
        default:
          content = `[${msg.type}] ${msg.content || ''}`;
      }

      return `[${time}] ${userDisplay}: ${content}`;
    }).join('\n');

    return `
–°–æ–∑–¥–∞–π –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –¥–ª—è —á–∞—Ç–∞ "${context.chatTitle}" –∑–∞ ${context.date}.

–°–æ–æ–±—â–µ–Ω–∏—è –∑–∞ –¥–µ–Ω—å (${context.totalMessages} —à—Ç.):
${messageTexts}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–∞–π–¥–∂–µ—Å—Ç—É:
1. –ù–∞—á–Ω–∏ —Å –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ ${context.targetUsername}
2. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º:
   - –¢–µ–º—ã: –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è
   - –ò—Ç–æ–≥–∏/—Ä–µ—à–µ–Ω–∏—è: –≤–∞–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏ –¥–æ–≥–æ–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
   - –ö—Ä—É–∂–∫–∏/–∞—É–¥–∏–æ: –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∏ –≤–∏–¥–µ–æ—Å–æ–æ–±—â–µ–Ω–∏–π —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏ –∏ –∞–≤—Ç–æ—Ä–∞
   - –ó–∞–±–∞–≤–Ω–æ–µ: –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã, –º–µ–º—ã, —Ä–µ–∞–∫—Ü–∏–∏
   - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –∑–∞ –¥–µ–Ω—å

3. –ë—É–¥—å –∫—Ä–∞—Ç–∫–∏–º, –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º
4. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
5. –ù–µ –ø—Ä–µ–≤—ã—à–∞–π 1200 —Å–∏–º–≤–æ–ª–æ–≤

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
${context.targetUsername} –°–Ω–æ–≤–∞ –Ω–µ –ø—Ä–æ—á–∏—Ç–∞–ª —á–∞—Ç, –ø–µ—Å? –°–æ—Å–∏ –æ–≥—Ä—ã–∑–∫–∏:

[—Ç–≤–æ–π –¥–∞–π–¥–∂–µ—Å—Ç –∑–¥–µ—Å—å]
`;
  }
}

/**
 * Fallback LLM Provider for when OpenAI is not available
 */
export class FallbackProvider implements LLMProvider {
  public async generateSummary(messages: ProcessedMessage[], context: SummaryContext): Promise<string> {
    logger.warn('Using fallback summary provider');
    
    const textMessages = messages.filter(m => m.type === 'text' && m.content);
    const voiceMessages = messages.filter(m => (m.type === 'voice' || m.type === 'video_note') && m.transcript);
    const mediaMessages = messages.filter(m => ['photo', 'video', 'document'].includes(m.type));

    const summary = `${context.targetUsername} –°–Ω–æ–≤–∞ –Ω–µ –ø—Ä–æ—á–∏—Ç–∞–ª —á–∞—Ç, –ø–µ—Å? –°–æ—Å–∏ –æ–≥—Ä—ã–∑–∫–∏:

üìù **–¢–µ–º—ã:** –û–±—Å—É–∂–¥–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:** ${context.totalMessages} —Å–æ–æ–±—â–µ–Ω–∏–π –∑–∞ –¥–µ–Ω—å
üé§ **–ì–æ–ª–æ—Å–æ–≤—ã–µ/–∫—Ä—É–∂–∫–∏:** ${voiceMessages.length} –∞—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏–π
üìé **–ú–µ–¥–∏–∞:** ${mediaMessages.length} —Ñ–∞–π–ª–æ–≤
üí¨ **–¢–µ–∫—Å—Ç–æ–≤—ã—Ö:** ${textMessages.length} —Å–æ–æ–±—â–µ–Ω–∏–π

_–î–µ—Ç–∞–ª—å–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ OpenAI API._`;

    return summary;
  }

  public async isAvailable(): Promise<boolean> {
    return true;
  }
}

/**
 * LLM Provider factory
 */
export class LLMProviderFactory {
  private static instance: LLMProvider | null = null;

  public static async getProvider(): Promise<LLMProvider> {
    if (!this.instance) {
      const openaiProvider = new OpenAIProvider();
      const isAvailable = await openaiProvider.isAvailable();
      
      if (isAvailable) {
        this.instance = openaiProvider;
        logger.info('Using OpenAI provider');
      } else {
        this.instance = new FallbackProvider();
        logger.warn('Using fallback provider - OpenAI not available');
      }
    }

    return this.instance;
  }

  public static reset(): void {
    this.instance = null;
  }
}
